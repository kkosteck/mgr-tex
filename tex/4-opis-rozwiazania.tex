\newpage % Rozdziały zaczynamy od nowej strony.

\section{Opis przeprowadzonych eksperymentów}
W celu generowania podpisów do obrazków wykorzystana została architektura składającą się z modułu kodującego oraz modułu dekodującego. W eksperymentach zostały wykorzystane różne konfiguracje modułów kodujących wraz z modułami dekodującymi.
\subsection{Wykorzystanie wstępnie wytrenowanych modeli}
Szeroką popularnością w dziedzinie trenowania modeli sieci neuronowych cieszy się technika przenoszenia wiedzy. Jest to technika w uczeniu maszynowym, w której model uczony jest na jednym zadaniu, a następnie wykorzystuje tę wiedzę do lepszego rozwiązania innego, zazwyczaj podobnego zadania. Może zostać ona podzielona na dwa kluczowe kroki:
\begin{itemize}
    \item Początkowe uczenie modelu na dużym zbiorze danych i zadaniu, na którym jest dostępna duża ilość informacji.
    \item  Dostosowanie modelu do nowego zadania. Parametry modelu są dostosowywane do specyfiki nowego zadania, a wagi nauczone podczas początkowe uczenia są używane jako punkt wyjścia.
\end{itemize}
W przypadku generowania podpisów do obrazków technikę przenoszenia wiedzy można zastosować poprzez wykorzystanie wcześniej wyuczonych modeli sieci splotowych w ramach modułu kodującego. Trenowanie splotowych sieci neuronowych od zera na dużym zbiorze danych może być czasochłonne i wymagać dużej ilości zasobów obliczeniowych. Wykorzystanie wstępnie wytrenowanych modeli pozwala uniknąć tego procesu ze względu na ich umiejętność ekstrakcji cech, co jest ich docelowym zadaniem w całej architekturze. Z tego względu treningowymi danymi wejściowymi były wcześniej przetworzone obrazy przez moduł kodujący -- trening polegał na uczeniu jedynie modułu dekodującego.

Wykorzystane moduły kodujące:
\begin{itemize}
    \item AlexNet \cite{alexnet},
    \item GoogLeNet \cite{googlenet},
    \item bardzo głęboka sieć neuronowa -- VGGNet \cite{vggnet},
    \item rezydualna bardzo głęboka sieć neuronowa -- ResNet \cite{resnet},
    \item Transformer wizyjny -- VIT \cite{vit}.
\end{itemize}
Ze względu na wykorzystanie wstępnie wytrenowanych wag modułów zostały one poddane modyfikacji -- ostatnia warstwa w pełni połączona została usunięta. Poprzez taką zmianę danymi wyjściowymi tychże sieci są dane potencjalnie zawierające wyodrębnione cechy obrazów.
Wykorzystane moduły dekodujące:
\begin{itemize}
    \item podstawowa rekurencyjna sieć neuronowa -- RNN \cite{rnn},
    \item LSTM \cite{lstm},
    \item GRU \cite{gru},
    \item Transformer \cite{transformer},
\end{itemize}
Każda kombinacja modułu kodującego wraz z modułem dekodującym została sprawdzona pod względem:
\begin{itemize}
    \item wydajności uczenia poprzez sprawdzenie czasu potrzebnego na przetworzenie przez architekturę treningowego zbioru danych,
    \item wydajności generowania podpisów, poprzez sprawdzenie czasu potrzebnego na przetworzenie testowego zbioru danych,
    \item efektywności poprzez sprawdzenie skuteczności generowania podpisów.
\end{itemize}
Wydajność testowania oraz skuteczność generowania podpisów została również sprawdzona dla dedykowanej architektury \cite{wang2022git} wykorzystującej transformer wizyjny wraz z klasycznym transformerem. W tym celu wykorzystane zostały wagi udostępnione przez autorów -- pozwoliło to na całkowite pominięcie etapu uczenia tejże sieci.
\subsection{Trenowanie pełnej architektury}
W celu sprawdzenia jak duże znaczenie ma wykorzystanie wstępnie wytrenowanych modułów kodujących, ich wydajność treningowa została porównana do wydajności uczenia pełnej architektury. Porównane zostały wszystkie wcześniej wymienione kombinacje modułów kodujących wraz z modułami dekodującymi. Oprócz tego do zbioru modułów dekodujących dodany został również podstawowy wariant splotowej sieci neuronowej.
\subsection{Wstępne przetwarzanie danych}
Dane wejściowe w postaci macierzy pikseli obrazów cyfrowych są normalizowane oraz ich wymiary są ujednolicane w celu uproszczenia obliczeń. Natomiast przetwarzanie języka naturalnego odbywa się poprzez tokenizację -- w tym celu został wykorzystany wcześniej wytrenowany model Distilbert \cite{distilbert}.
\subsection{Metryki}
Oprócz parametrów dotyczących wydajności trenowania oraz testowania podanych rozwiązań sprawdzona została również skuteczność otrzymanych wyników. Ze względu na analogiczne dane w ramach ewaluacji wyników w dziedzinie generowania podpisów do obrazków wykorzystywane są metryki z dziedziny tłumaczenia maszynowego. Wybrane metryki:
\begin{itemize}
    \item BLEU (ang. Bilingual Evaluation Understudy) \cite{bleu} -- metryka oryginalnie wywodząca się z dziedziny tłumaczenia maszynowego, jednakże ze względu na taki sam format danych, idealnie pasuje również do ewaluacji wyników generowania podpisów do obrazów,
          % \item METEOR (ang. Metric for Evaluation of Translation with Explicit ORdering) \cite{meteor} -- metryka będąca rozwinięciem metryki BLEU. Odznacza się lepszą oceną korelacji na poziomie zdań, a nie tak jak w~przypadku BLEU, na~poziomie całego korpusu.
    \item CIDEr (ang. Consensus-based Image Description Evaluation) \cite{cider} -- dedykowana metryka do oceny jakości generowanych opisów obrazów.
\end{itemize}
\subsection{Wykorzystane środowiska}
W celu porównania wpływu użytych jednostek obliczeniowych na efektywność badanych architektury wykorzystane zostały różne karty graficzne:
\begin{itemize}
    \item NVIDIA GeForce GTX 1650 4GB -- jednostka GPU,
    \item NVIDIA Tesla T4 16 GB -- jednostka GPU,
    \item Intel Core i7-1280P -- jednostka CPU.
\end{itemize}
\subsection{Implementacja}
Docelowa architektura została zaimplementowana przy użyciu gotowych modeli sieci neuronowych zawartych w bibliotekach PyTorch \cite{pytorch} oraz Transformers \cite{wolf-etal-2020-transformers} dostępnych w języku programowania Python.
\subsection{Zbiory danych}
Istnieje wiele zbiorów danych zawierających obrazy wraz z ich opisami. Jednymi z najpopularniejszych są:
\begin{itemize}
    \item MS COCO \cite{mscoco} -- składa się on z ponad 120 tysięcy zdjęć.
    \item Flickr \cite{flickr30k} -- posiada on mniej zdjęć niż zbiór MS COCO, ponieważ jego szeroki wariant zawiera ich 30 tysięcy, natomiast węższy 8 tysięcy.
\end{itemize}
Ze względu na konieczność wytrenowania dużej liczby architektur niezwykle istotne jest dokonanie tego w sensownym oknie czasowym, co może być niewykonalne przy wykorzystaniu zbioru MS COCO. Z tego względu został wykorzystany węższy wariant zbioru Flickr zawierający 8 tysięcy zdjęć. Ten wybór pozwolił również sprawdzić skuteczność modelu GIT, bez wcześniejszego go wytrenowania, posługując się jedynie modelem udostępnionym przez autorów, który został wytrenowany na zbiorze MS COCO.
